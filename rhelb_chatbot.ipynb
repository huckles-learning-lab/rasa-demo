{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMie+gUfzELHyIWYV0IMN0R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huckles-learning-lab/rasa-demo/blob/main/rhelb_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# RHELB - Bot auf Rasa basierend mit Haystack-Elasticsearch integration und Leaf\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "##Das Skript erstellt einen Chatbot, der mithilfe von Machine-Learning, Deep-Learning und neuronalen Netzwerken sowie AI betrieben wird. Der Chatbot nutzt Rasa, Haystack, Elasticsearch und Leaf, um Nutzeranfragen zu beantworten.\n",
        "\n",
        "Folgende Ordnerstrucktur wird angelegt:\n",
        "\n",
        "    domain.yml\n",
        "    config.yml\n",
        "    data/nlu.yml\n",
        "    data/rules.yml\n",
        "    actions/actions.py\n",
        "\n",
        "\n",
        "\n",
        "Installieren Sie Rasa und starten Sie die Haystack REST API und einen Demo DocumentStore über Docker:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ji1wV00Rq9u6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# #Setting up your environment"
      ],
      "metadata": {
        "id": "V7jNUnO85HOM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Python Environment Setup\n",
        "Check if your Python environment is already configured:"
      ],
      "metadata": {
        "id": "3i0IbQcz5fPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 --version\n",
        "!pip3 --version"
      ],
      "metadata": {
        "id": "-Nq9RGNNrr8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fetch the relevant packages using apt, and install virtualenv using pip."
      ],
      "metadata": {
        "id": "9_mVx-Z557bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt update\n",
        "!apt install python3-dev python3-pip"
      ],
      "metadata": {
        "id": "wjWmj0bO5TQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Virtual Environment Setup\n",
        "Create a new virtual environment by choosing a Python interpreter and making a ./venv directory to hold it:"
      ],
      "metadata": {
        "id": "B8ClBLYw5Khx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install python3.8-venv\n",
        "!python3 -m venv ./venv"
      ],
      "metadata": {
        "id": "wyz4ywZe5k7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And activate the virtual environment:"
      ],
      "metadata": {
        "id": "tzvCdSKc6G6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!source ./venv/bin/activate"
      ],
      "metadata": {
        "id": "JNsjuYBj6GYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "cG-8KQkW6O5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# #Installing Rasa Open Source\n",
        "\n",
        "First make sure your pip version is up to date:"
      ],
      "metadata": {
        "id": "d3c-hpjb6k_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -U pip"
      ],
      "metadata": {
        "id": "ofl4f4vZ6Pki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To install Rasa Open Source:"
      ],
      "metadata": {
        "id": "29LhGYd462OI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install rasa"
      ],
      "metadata": {
        "id": "BZrHTdZq679L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Congratulations! You have successfully installed Rasa Open Source!\n",
        "\n",
        "You can now create a new project with:"
      ],
      "metadata": {
        "id": "eXoLFEGe7CGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rasa init"
      ],
      "metadata": {
        "id": "5UhdFNrB7HmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It creates the following files:"
      ],
      "metadata": {
        "id": "xLOPn3_H7M-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ".\n",
        "├── actions\n",
        "│   ├── __init__.py\n",
        "│   └── actions.py\n",
        "├── config.yml\n",
        "├── credentials.yml\n",
        "├── data\n",
        "│   ├── nlu.yml\n",
        "│   └── stories.yml\n",
        "├── domain.yml\n",
        "├── endpoints.yml\n",
        "├── models\n",
        "│   └── <timestamp>.tar.gz\n",
        "└── tests\n",
        "   └── test_stories.yml"
      ],
      "metadata": {
        "id": "8VIxs5b27jCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "1E6odeWsaoIS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# #Farm-Haystack & Elasticsearch\n",
        "\n"
      ],
      "metadata": {
        "id": "MMvvUGfo_yGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m venv ./venv2\n",
        "!source ./venv2/bin/activate\n",
        "!pip install --upgrade pip\n",
        "!pip install elasticsearch\n",
        "!pip install 'farm-haystack[all]' ## or 'all-gpu' for the GPU-enabled dependencies"
      ],
      "metadata": {
        "id": "J3KbMMLS7vd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# #Leaf-Framework"
      ],
      "metadata": {
        "id": "mLS7t8gEA4tH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m venv ./venv-leaf\n",
        "!source ./venv-leaf/bin/activate\n",
        "!pip install leaf"
      ],
      "metadata": {
        "id": "EV3urGujA7-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "7LZIwQN-BB3k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# #Main Block"
      ],
      "metadata": {
        "id": "RGzv3znaBGmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd rasa\n",
        "\n",
        "import rasa\n",
        "from rasa.model import Trainer\n",
        "from rasa.shared.nlu.training_data.loading import load_data\n",
        "from rasa.nlu.model import Interpreter\n",
        "from rasa.core.agent import Agent\n",
        "from rasa.core.training import interactive\n",
        "from rasa.core import config\n",
        "\n",
        "# Lade Trainingsdaten im Rasa NLU-Format\n",
        "training_data = load_data(\"data/nlu.md\")\n",
        "\n",
        "# Trainiere das NLU-Modell\n",
        "trainer = Trainer(config.load(\"config.yml\"))\n",
        "trainer.train(training_data)\n",
        "model_directory = trainer.persist(\"models/nlu\", fixed_model_name=\"current\")\n",
        "\n",
        "# Trainiere das Core-Modell\n",
        "agent = Agent(\"domain.yml\", policies=config.load(\"config.yml\"))\n",
        "data = agent.load_data(\"data/stories.md\")\n",
        "agent.train(data)\n",
        "agent.persist(\"models/dialogue\")\n",
        "\n",
        "# Initialisiere Interpreter\n",
        "interpreter = Interpreter.load(model_directory)"
      ],
      "metadata": {
        "id": "PdlS04MXBDGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.document_store.elasticsearch import ElasticsearchDocumentStore\n",
        "from haystack.file_converter.txt import TextConverter\n",
        "from haystack.retriever.sparse import ElasticsearchRetriever\n",
        "\n",
        "# Erstelle Elasticsearch-Index\n",
        "document_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\", index=\"document\")\n",
        "document_store.delete_documents()\n",
        "\n",
        "# Konvertiere Textdaten und lade sie in den Index\n",
        "converter = TextConverter(remove_numeric_tables=True)\n",
        "document_store.write_documents(converter.convert(file_path=\"data/text_data.txt\"), index=\"document\")\n",
        "\n",
        "# Erstelle Haystack-Document-Store- und Retrieval-Instanzen\n",
        "document_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\", index=\"document\")\n",
        "retriever = ElasticsearchRetriever(document_store=document_store)\n"
      ],
      "metadata": {
        "id": "IQe25TrNBVqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from leaf.api import Agent, Environment\n",
        "from leaf.environment.vectorized import Vectorized\n",
        "from haystack.retriever.sparse import ElasticsearchRetriever\n",
        "from rasa.core.agent import Agent as RasaAgent\n",
        "\n",
        "# Erstelle Leaf-Modell für den Chatbot\n",
        "environment = Environment(Vectorized(environment_size=32))\n",
        "retriever = ElasticsearchRetriever(document_store=document_store)\n",
        "rasa_agent = RasaAgent.load(\"models/dialogue\", interpreter=interpreter)\n",
        "agent = Agent(environment, [retriever, rasa_agent])\n",
        "\n",
        "# Trainiere das Leaf-Modell\n",
        "agent.train(epochs=10)"
      ],
      "metadata": {
        "id": "fDgI4qZsBbvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rasa_sdk import Action, Tracker\n",
        "from rasa_sdk.executor import CollectingDispatcher\n",
        "from haystack import Finder\n",
        "from haystack.reader.farm import FARMReader\n",
        "from haystack.utils import print_answers\n",
        "from leaf.query import LeafQuery\n",
        "from leaf.result import LeafResult\n",
        "from leaf.model import LeafModel\n",
        "import json\n",
        "\n",
        "class SearchAction(Action):\n",
        "    def name(self) -> Text:\n",
        "        return \"action_search\"\n",
        "\n",
        "    def run(self, dispatcher: CollectingDispatcher,\n",
        "            tracker: Tracker,\n",
        "            domain: Dict[Text, Any]) -> List[Dict[Text, Any]]:\n",
        "\n",
        "        # Extract the user's message from the tracker object\n",
        "        user_message = tracker.latest_message.get('text')\n",
        "\n",
        "        # Create a Haystack Finder object to get the answers\n",
        "        document_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\", index=\"faq\")\n",
        "        retriever = ElasticsearchRetriever(document_store=document_store)\n",
        "        reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=False)\n",
        "        finder = Finder(reader, retriever)\n",
        "\n",
        "        # Use the Haystack Finder object to get the answers\n",
        "        prediction = finder.get_answers(question=user_message, top_k_retriever=3, top_k_reader=3)\n",
        "\n",
        "        # Create a Leaf Query object to get the best answer\n",
        "        leaf_query = LeafQuery(\n",
        "            question=user_message,\n",
        "            context={\n",
        "                \"answers\": [answer.to_dict() for answer in prediction[\"answers\"]],\n",
        "                \"meta\": prediction[\"meta\"],\n",
        "            },\n",
        "        )\n",
        "\n",
        "        # Create a Leaf Model object to make the query\n",
        "        leaf_model = LeafModel(model_path=\"models/leaf_model\")\n",
        "        leaf_result = leaf_model.predict(leaf_query)\n",
        "\n",
        "        # Convert the result to a dictionary\n",
        "        result_dict = json.loads(leaf_result.to_json())\n",
        "\n",
        "        # Get the best answer from the result\n",
        "        answer = result_dict['answers'][0]['answer']\n",
        "\n",
        "        # Send the answer back to the user\n",
        "        dispatcher.utter_message(text=answer)\n",
        "\n",
        "        return []"
      ],
      "metadata": {
        "id": "E52OuyiFBlBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "GKNjSbHPZ-qA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# #Leaf konfigurieren und Modell trainieren"
      ],
      "metadata": {
        "id": "C9oLmtjRB_SO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importieren der benötigten Pakete\n",
        "from leaf.modules import Module\n",
        "from leaf.data import Dataset\n",
        "from leaf.optimizers import Adam\n",
        "from leaf.losses import CrossEntropyLoss\n",
        "from leaf.models import NeuralNetwork\n",
        "from leaf.callbacks import Callback, AccuracyCallback\n",
        "from leaf.metrics import accuracy\n",
        "\n",
        "# Definieren der Modellparameter\n",
        "num_classes = 2\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# Definieren der Trainingsparameter\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Erstellen des Datasets\n",
        "dataset = Dataset.from_elasticsearch(\n",
        "    es_host=es_host,\n",
        "    es_port=es_port,\n",
        "    es_index=es_index,\n",
        "    query={\"query\": {\"match_all\": {}}},\n",
        "    fields=[\"text\"],\n",
        "    target_field=\"label\",\n",
        "    num_samples=1000,\n",
        ")\n",
        "\n",
        "# Erstellen des Moduls\n",
        "module = Module(\n",
        "    NeuralNetwork(num_classes=num_classes, input_shape=input_shape),\n",
        "    loss=CrossEntropyLoss(),\n",
        "    optimizer=Adam(learning_rate),\n",
        ")\n",
        "\n",
        "# Erstellen des Callbacks\n",
        "callback = AccuracyCallback(metric_fn=accuracy, target=1.0)\n",
        "\n",
        "# Trainieren des Modells\n",
        "module.fit(\n",
        "    dataset=dataset,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=[callback],\n",
        ")\n"
      ],
      "metadata": {
        "id": "Qh_kyRcqB7RN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AARyQ9t11TcJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}